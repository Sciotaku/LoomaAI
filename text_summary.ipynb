{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from pdfminer.high_level import extract_text\n",
    "from io import StringIO\n",
    "import fitz\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Tokenize the data\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples['article']]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['highlights'], max_length=150, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Tokenize the data\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples['article']]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['highlights'], max_length=150, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text_to_fp\n",
    "from io import StringIO\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, start_page, end_page):\n",
    "    text = \"\"\n",
    "    output = StringIO()\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        extract_text_to_fp(f, output, page_numbers=range(start_page-1, end_page))\n",
    "        text = output.getvalue()\n",
    "    return text\n",
    "\n",
    "# Define the path to the PDF and the pages to extract\n",
    "pdf_path = \"looma_sample_book.pdf\"  # Update this to the path of your PDF file\n",
    "start_page = 1  # Update this to the start page of Chapter 1\n",
    "end_page = 2  # Update this to the end page of Chapter 1\n",
    "\n",
    "# Extract text from the specified pages\n",
    "chapter_text = extract_text_from_pdf(pdf_path, start_page, end_page)\n",
    "print(\"Extracted Chapter Text:\")\n",
    "print(chapter_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./results/t5_fine_tuned\"  # Path to the fine-tuned model\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Function to generate a summary\n",
    "def generate_summary(chapter_text):\n",
    "    inputs = tokenizer(\"summarize: \" + chapter_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate and print the summary for the extracted chapter text\n",
    "summary = generate_summary(chapter_text)\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fig. 23.\n",
      "Microsoft Stock Price Prediction with Sentiment\n",
      "Fig. 24.\n",
      "Microsoft Stock Price Prediction without Sentiment\n",
      "• Without sentiment, Test MAE: 3.86\n",
      "For Facebook, the inclusion of sentiment scores notably\n",
      "enhanced the model’s forecasting accuracy, as indicated\n",
      "by the lower RMSE and MAE values. This improvement\n",
      "underscores the relevance of social media sentiment in\n",
      "predicting Facebook’s stock price movements, highlighting\n",
      "the importance of public perception and sentiment trends\n",
      "in shaping the company’s market valuation.\n",
      "Fig. 25.\n",
      "Facebook Stock Price Prediction with Sentiment\n",
      "Fig. 26.\n",
      "Facebook Stock Price Prediction without Sentiment\n",
      "13\n",
      "\n",
      "Analyzing impact of twitter sentiment on stock market dynamics using\n",
      "spectral clustering and deep learning\n",
      "Vagmin Viswanathan, Rahul Gupta\n",
      "Math 76.01: Topics in Applied Math\n",
      "Department of Mathematics, Dartmouth College\n",
      "Abstract— Modern social media platforms have become\n",
      "influential forums for discussing and disseminating public\n",
      "opinion\n",
      "on\n",
      "topics\n",
      "like\n",
      "the\n",
      "financial\n",
      "markets.\n",
      "Previous\n",
      "literature has extensively demonstrated the impact of investor\n",
      "sentiment\n",
      "on\n",
      "stock\n",
      "price\n",
      "movements.\n",
      "This\n",
      "study\n",
      "seeks\n",
      "to\n",
      "further\n",
      "characterize\n",
      "the\n",
      "underlying\n",
      "structure\n",
      "of\n",
      "the\n",
      "relationship between time series data of equity price metrics\n",
      "and sentiment streams during the pandemic. We aggregated\n",
      "web scraped financial tweets and employed natural language\n",
      "processing techniques for sentiment analysis and labeling. We\n",
      "then constructed a network and employed spectral clustering\n",
      "to explore structures within the data. Then, to ascertain\n",
      "the predictive value of our sentiment metrics, we utilized\n",
      "regression techniques, random forest analysis, and LSTM\n",
      "neural networks. These allowed us to determine equities\n",
      "impacted the most by investor sentiment and enhanced our\n",
      "model’s predictive power of future equity prices. The findings\n",
      "of this research provide insights into the dynamics of social\n",
      "media sentiment in financial forecasting, offering a new\n",
      "perspective on market analysis.\n",
      "Index Terms— sentiment analysis, spectral clustering, LSTM\n",
      "neural network, random forest classifier\n",
      "I. INTRODUCTION\n",
      "The stock market is a complex and dynamic system, in-\n",
      "fluenced by a myriad of factors ranging from economic in-\n",
      "dicators and corporate performance to geopolitical events\n",
      "and investor sentiment. At its core, the movement of stock\n",
      "prices reflects the collective actions of buyers and sellers\n",
      "in the market, driven by their expectations for future earn-\n",
      "ings and company growth prospects. Traditional financial\n",
      "theories, such as the Efficient Market Hypothesis (EMH)\n",
      "[1], suggest that stock prices at any given time fully reflect\n",
      "all available information. However, the proliferation of\n",
      "social media platforms and no fee retail trading apps since\n",
      "2020 have allowed investor sentiment to be disseminated\n",
      "and represented in the financial markets to an ever greater\n",
      "extent.\n",
      "In particular, platforms like X1 (formerly known as\n",
      "Twitter) have drawn investors to its significant sources\n",
      "of real-time news, opinions, and sentiment, accessible to\n",
      "millions of users worldwide. The immediacy and breadth\n",
      "of information available on social media have the poten-\n",
      "tial to influence public perception and investor behavior,\n",
      "thereby affecting stock prices. Recent advancements in\n",
      "Natural Language Processing (NLP) and machine learning\n",
      "have paved the way for sophisticated sentiment analysis\n",
      "1https://twitter.com/\n",
      "of these platforms. These techniques enable the extrac-\n",
      "tion of subjective information from tweets, allowing the\n",
      "application of traditional data science analysis to come to\n",
      "bear.\n",
      "This paper is structured as follows: Section II sum-\n",
      "marizes the findings from the existing literature. Sec-\n",
      "tion III explains the data collection and prepocessing\n",
      "process. Section IV describes the models and methods\n",
      "used for our analysis. Primarily we focus on network\n",
      "analysis techniques to understand the structure of our\n",
      "data and machine learning techniques to understand\n",
      "feature importance. In Section V, the results of our models\n",
      "have been provided; followed by a discussion of their\n",
      "significance for the literature. In Section VI, we discuss\n",
      "our findings and in Section VII we conclude our paper\n",
      "with acknowledgements in Section VIII and references\n",
      "in Section IX. The Appendix provides further details on\n",
      "additional select companies. Our code and processed data\n",
      "is also documented and accessible on GitHub2.\n",
      "II. LITERATURE SURVEY\n",
      "According to Giachanou and Crestani, Twitter Sentiment\n",
      "Analysis (TSA) has been an exciting field of research\n",
      "since 2009 [2] where foundational papers have established\n",
      "natural language processing and data mining techniques.\n",
      "The Twitter API (Application Programming Interface)3 has\n",
      "long provided open access to millions of user generated\n",
      "tweets that could be scrapped and analyzed. Giachanou\n",
      "and Crestani describe in their survey of machine learning\n",
      "methods how TSA is difficult because of the 140 character\n",
      "limit, informal style, and unique word embedding struc-\n",
      "ture [2]. Traditional sentiment analysis literature typically\n",
      "tries to understand sentiment through text polarity. TSA\n",
      "methods require twitter specific stop words, tokenizers,\n",
      "word embedding structures, multilingual and multi-modal\n",
      "approaches. Advances in deep learning models and la-\n",
      "beled datasets around 2012 has enabled the field to ma-\n",
      "ture beyond these fundamental challenges. Furthermore,\n",
      "Wiebe et al. demonstrates how to create sentiment time\n",
      "series where sentiment scores were smoothed by taking\n",
      "the daily positive versus negative ratio with a moving\n",
      "average window of the past k days [3].\n",
      "2https://github.com/\n",
      "3In recent years the takeover and re-branding of the platform as X has\n",
      "severely limited access to data mining\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "\n",
    "# Load PDF\n",
    "pdf_path = \"Math_76_Paper.pdf\"  # Replace with the path to your PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "def extract_text_from_pdf(pdf_document, start_page, end_page):\n",
    "    text_by_page = []\n",
    "    for page_num in range(start_page - 1, end_page):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        if not text.strip():  # If no text found, use OCR\n",
    "            images = convert_from_path(pdf_path, first_page=page_num+1, last_page=page_num+1)\n",
    "            text = pytesseract.image_to_string(images[0])\n",
    "        text_by_page.append(text)\n",
    "    return text_by_page\n",
    "\n",
    "# Extract text\n",
    "chapter_1_text = extract_text_from_pdf(pdf_document, 0, 1)\n",
    "chapter_1_text = \"\\n\".join(chapter_1_text)\n",
    "print(chapter_1_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc58ca04d683454585e45253879916d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_name = \"facebook/bart-large-cnn\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Chapter 1:\n",
      "For Facebook, the inclusion of sentiment scores notablyenhanced the model’s forecasting accuracy, as indicated by the lower RMSE and MAE values. Modern social media platforms have becomeinfluential forums for discussing and disseminating publicopinion. This study highlights the importance of public perception and sentiment trends in shaping the company's market valuation.\n"
     ]
    }
   ],
   "source": [
    "# def generate_summary(text, max_length=150, num_beams=5):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "#     summary_ids = model.generate(inputs.input_ids, max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
    "#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#     return summary\n",
    "\n",
    "# # Generate summary for Chapter 1\n",
    "# chapter_1_summary = generate_summary(chapter_1_text[:1024])  # Truncate text to 1024 tokens if too long\n",
    "\n",
    "# print(f\"Summary of Chapter 1:\\n{chapter_1_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# url = \"http://localhost:11434/api/chat\"  # Ensure this is the correct URL for your local Llama3 instance\n",
    "\n",
    "# def llama3(prompt):\n",
    "#     data = {\n",
    "#         \"model\": \"llama3\",\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": prompt\n",
    "#             }\n",
    "#         ],\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "    \n",
    "#     headers = {\n",
    "#         'Content-Type': 'application/json'\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "#     return response.json()['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Chapter 1:\n",
      "The text describes a study on predicting Microsoft stock prices using Twitter sentiments. The researchers built upon previous studies that showed the impact of investor sentiment on financial markets and introduced a novel approach that uses network analysis techniques to understand the structure of correlations between Twitter sentiments and stock prices.\n",
      "\n",
      "The study collected Twitter data related to financial markets during the COVID-19 pandemic, which led to high market volatility and significant social media activity. The researchers used an existing dataset of around a million finance-related tweets from April 9, 2020, to July 16, 2020, as well as other datasets.\n",
      "\n",
      "To create a sentiment time series, the researchers cleaned the Twitter data by removing duplicates, spam, and non-English tweets, and tagged each tweet with the company mentioned. They then extracted the date of each tweet and created a distribution of tweets across companies, showing that most tweets were about a handful of tech companies like Microsoft.\n",
      "\n",
      "The study also used Long Short-Term Memory (LSTM) models to capture the complex dynamics of market behaviors and temporal dependencies in stock price movements. The researchers aimed to predict future stock prices using a random forest classifier and to understand the structure of correlations between Twitter sentiments and stock prices through network analysis techniques.\n",
      "\n",
      "Overall, the study aimed to improve upon previous studies by introducing a novel approach that uses network analysis techniques to understand the structure of correlations between Twitter sentiments and stock prices.\n"
     ]
    }
   ],
   "source": [
    "# # Generate summary for Chapter 1\n",
    "# chapter_1_summary = llama3(f\"Summarize the following text: {chapter_1_text}\")\n",
    "\n",
    "# print(f\"Summary of Chapter 1:\\n{chapter_1_summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—— Scientific Study\n",
      "\n",
      "The scientific study includes scientific facts, theories,\n",
      "models, experiments and physical situations. It studies various\n",
      "objects in nature in a planned and organized way. It also logically\n",
      "investigates the various phenomena based on the\n",
      "scientific method and empirical or measurable evidence. Various\n",
      "causative factors have a role in different events and phenomena that\n",
      "have occurred in nature. The causative factor, characteristic, or trait\n",
      "that has a direct or indirect relationship with an event or a phenom-\n",
      "enonis known as a variable.\n",
      "\n",
      "1.1 Variables of scientific research\n",
      "\n",
      "When we see a phenomenon or change, we are curious to know\n",
      "why it happens, what factors areinvolved, and how they have\n",
      "affected that event or phenomenon. Such curiosity helps us to\n",
      "predict the result of an action correctly. For instance, if we see\n",
      "a wilted potted plant in the garden, we want to know why is it\n",
      "wilted.Is it because of lack of water, overexposure to bright sun,\n",
      "or someother reasons? To find out the answer, we try to find\n",
      "the effects of keeping the plant in theshade or watering it or\n",
      "doingsome other things. With the help of knowledge and\n",
      "experience obtained fromsuch curiosity or interest, we can\n",
      "easily guess what could be the condition of the plant if we forget to\n",
      "water it or keep it in the shade on a hot day.Then we can take the\n",
      "necessary measures to save it.\n",
      "\n",
      "For each incident or change, there is always cause and\n",
      "effect. In the aforementioned example, either lack of water or\n",
      "excessive heat of the sun is the causative factor whereas wilting is the\n",
      "effect. The effect depends on the causal factors. For example, the\n",
      "rigidity of the stem of a plant depends on the amount of water in\n",
      "it. Therefore, for the right estimation, it is essential to know the\n",
      "\n",
      "Science and Technology, Grade 10 &\n",
      "\n",
      "relationship between the magnitude of the causative factor and the\n",
      "magnitude of the effect.\n",
      "\n",
      "This relation can be established through experiments. The task of a\n",
      "scientist is to set up a relationship between various physical quanti-\n",
      "ties and ultimately find out how nature works.\n",
      "\n",
      "Activity 1.1\n",
      "Title: Making catapult from a rubber band\n",
      "\n",
      "Materials required: rubber band (about 5 cm long), a 15 cm long\n",
      "ruler, small pieces of paper (about 2cm length and 2 cm breadth) and\n",
      "measuring tape\n",
      "\n",
      "Method\n",
      "\n",
      "1. Wrap the pieces of paper into\n",
      "a cylinder-like form and fold\n",
      "them in the middle. It func-\n",
      "tions as a projectile or bullet\n",
      "for a catapult.\n",
      "\n",
      "2. Hook the rubber band into\n",
      "two fingers of one hand (e.g.,\n",
      "thumb and forefinger), as Figure 1.1\n",
      "shown in the figure.\n",
      "\n",
      "3. Hold the paper bullet within two segments of the rubber band\n",
      "and stretch the rubber band.\n",
      "\n",
      "4. Ask your friend to measure the extension of the rubber band\n",
      "(distance from the fingers to the paper bullet). Make the distance\n",
      "4cm.\n",
      "\n",
      "5. Release the paper bullet. It will fly away from the catapult. Mea-\n",
      "sure the distance covered by the paper bullet.\n",
      "\n",
      "6. Note down the extension of the rubber band and the distance\n",
      "travelled by the paper bullet.\n",
      "\n",
      "Science and Technology, Grade 10\n",
      "\n",
      "\n",
      "7. Now, stretch the rubber band 6 cm and launch the paper bullet.\n",
      "Measure the distance travelled by the bullet. Repeat this for the\n",
      "\n",
      "extension of 8 cm and 10 cm.\n",
      "\n",
      "S.N. |Extension of _rubber|Distance travelled by the paper\n",
      "band(cm) bullet (cm)\n",
      "\n",
      "Ls 4\n",
      "\n",
      "2 6\n",
      "EA FG\n",
      "ja fio\n",
      "\n",
      "Scientific research involves changing the magnitude of one physical\n",
      "quantity and observing how this change brings changes in another\n",
      "physical quantity. For example: in the above experiment, we studied\n",
      "how the extension (stretch) of the rubber band affects the distance\n",
      "travelled by the paper bullet. Here, the extension of the rubber band\n",
      "and the distance covered by the bullet are both physical quanti-\n",
      "ties and their magnitude are different in each experiment. Such\n",
      "physical quantities are called variables because their value or magni-\n",
      "tude varies each time. The elements (physical quantities) that change\n",
      "or may change in an experiment are called variables of the experi-\n",
      "ment or research. In the above experiment stretching of the rubber\n",
      "band and the distance covered by the paper bullet are the variables\n",
      "of that experiment. The thickness of the rubber band and the size of\n",
      "the paper bullet could also have been changed in that experiment.\n",
      "Therefore, these are also the variable of the research.\n",
      "\n",
      "Each variable has a name and is represented by a symbol for ease\n",
      "of writing. The relation between variables is expressed interms of\n",
      "a mathematical formula. For example: If the extension or stretch of\n",
      "rubber is denoted by ‘e’and the distance travelled by the paper piece\n",
      "\n",
      "is denoted by ‘x’, the relation between them is x « e.\n",
      "\n",
      "Types of variables\n",
      "\n",
      "Usually, variables are classified into three types: independent vari-\n",
      "able, dependent variable and controlled variable.\n",
      "\n",
      "Science and Technology, Grade 10 &\n",
      "\n",
      "a. Independent variable\n",
      "\n",
      "During a scientific experiment or research, the researcher manipu-\n",
      "lates or changes a variable in a particular amount and measures the\n",
      "changes in another variable. The change made by the experimenter or\n",
      "researcher is the causative factor and subsequent change in another\n",
      "variable is the effect.\n",
      "\n",
      "In the experiment above, stretched rubber band throws the paper\n",
      "bullet. The extension of the rubber band is the causative factor and\n",
      "the distance travelled by the paper is the effect. The researcher or\n",
      "experimenter is free to decide the degree of extension of the rubber\n",
      "band. The variable which can be manipulated by a researcher is called\n",
      "the independent variable. In activity 1.1, the extensionof the rubber\n",
      "band is the independent variable.\n",
      "\n",
      "Causative factors related to the experiment are independent variables.\n",
      "For example, the amount of fertilizer, sunlight and water can be the\n",
      "independent variables for the growth of a plant.\n",
      "\n",
      "b. Dependent variable\n",
      "\n",
      "In experiment 1.1, the researcher cannot tell the distance covered\n",
      "by the piece of paper directly because it depends on the amount of\n",
      "stretching of the rubber band. Such a variable is called a dependent\n",
      "variable. So dependent variable is the variable whose value depends\n",
      "upon the value of anothervariable and the experimenter cannot predict\n",
      "or determine its value directly.For example.in activity 1.1 the distance\n",
      "covered by the paper bullet is the dependent variable. Similarly, while\n",
      "observing the effect of sunlight on the growth and development of\n",
      "the plant, the amount of sunlight is the independent variable and the\n",
      "height or growth of the plant is the dependent variable.\n",
      "\n",
      "Cc. Controlled variable\n",
      "\n",
      "In some experiments or research, there may be more than two vari-\n",
      "ables. Each variable influences the result of an experiment or research.\n",
      "Thus, it isnot possible to determine which variable is responsible\n",
      "for the change in the results or findings. In such a situation, it is\n",
      "difficult to draw conclusion. The conclusion might even not be valid or\n",
      "\n",
      "ae Science and Technology, Grade 10\n",
      "\n",
      "reliable. Therefore, to make the finding of the experiment valid,\n",
      "reliable and accurate, variables other than the specified independent\n",
      "variable and dependent variable should be controlled so that they\n",
      "do not affect the result. Such variables which are taken into control\n",
      "throughout the experiment or research are known as the controlled\n",
      "variables.\n",
      "\n",
      "In activity 1.1, the thickness of the rubber band and the size of the\n",
      "paper bullet should be kept the same throughout the experiment.\n",
      "\n",
      "If different rubber band sare used at each activity, the result will not\n",
      "be valid. Hence, for this experiment, the thickness of the rubber band\n",
      "and the size of the paper bullet are the controlled variables. Similarly,\n",
      "while we are observing the effect of light on plant growth, all plants\n",
      "should be of uniform size at the beginning of the experiment. Air,\n",
      "water and manure supplied to these plants should also be kept uniform\n",
      "throughout the experiment. So,the initial size of plants, air, water,\n",
      "and manure supplied to them are the controlled variables. In the same\n",
      "way, if we are studying the rate of a chemical reaction between the\n",
      "surface area of limestone and acid, the acid used each time should\n",
      "have the same concentration and the quantity and weight of limestone\n",
      "should also be kept the same. In this experiment, surface area is the\n",
      "independent variable, the rate of reaction is the dependent variable\n",
      "and the concentration of acid, quantity and weight of limestone are\n",
      "the controlled variables. Controlling such variables requires special\n",
      "arrangements while formulating the design of the experiment.\n",
      "\n",
      "In Activity 1.1\n",
      "\n",
      "Independent variable : extensionof rubber band\n",
      "\n",
      "Dependent variable _: distance travelled by paper bullet\n",
      "Controlled variable _: thickness of rubber band and size of the paper\n",
      "bullet\n",
      "\n",
      "Other examples of thevariable types mentioned above are listed in\n",
      "the table below:\n",
      "\n",
      "Science and Technology, Grade 10 &\n",
      "\n",
      "Independent | Dependent Controlled\n",
      "variable (what | variable (What | variable (what\n",
      "Ican change) |I observe) I keep the\n",
      "same\n",
      "\n",
      "Relation of a | Magnitude Amount of water\n",
      "\n",
      "rotating knob | of rotation the water flow | pressure\n",
      "\n",
      "of atap and_ | of knob (in per minute (in\n",
      "\n",
      "the rate of degree) litre)\n",
      "\n",
      "flow of the\n",
      "\n",
      "water\n",
      "\n",
      "Relation of || Amount of Number of Number of\n",
      "electricity electric cur- | pinsattracted | turns in the\n",
      "and magne- |rent(inam-_ |by the electro-| solenoid, size\n",
      "tism in a pere) magnet of the pin\n",
      "\n",
      "solenoid\n",
      "Effect of Temperature | Amount of Amount of\n",
      "heaton the |ofwater(in |completely water (always\n",
      "solubility of | degree cel- dissolved 100 grams)\n",
      "sugar sius) sugar in water\n",
      "(in grams)\n",
      "The immedi- |Duration of | | Number of Type of\n",
      "ate effect of | physical exer- | heartbeats physical\n",
      "physical ex- | cise (in min- exercise, the\n",
      "ercise on the | utes) interval be-\n",
      "heartbeat tween the end\n",
      "of exercise,\n",
      "and count of\n",
      "heartbeats\n",
      "\n",
      "Things to be considered about variables\n",
      "\n",
      "1. There should be only one independent variable in research or\n",
      "an experiment.\n",
      "\n",
      "2. There should be only one dependent variable in research or an\n",
      "experiment.\n",
      "\n",
      "3. Except for the specified independent variable and dependent\n",
      "variable, other variables should be controlled.\n",
      "\n",
      "Science and Technology, Grade 10\n",
      "\n",
      "\n",
      "4, While expressing the relation between variables in an equation,\n",
      "usually, the dependent variable is written on the left side of the\n",
      "equation and the independent variable is written on the right\n",
      "side. Hence, the independent variable is sometimes called a\n",
      "right variable and the dependent variable is called the left vari-\n",
      "able. For example,if we study how the distance covered by a\n",
      "moving object varies with time, then the mathematical equation\n",
      "of their relationship will be s =vt. Where distance travelled (s)\n",
      "is the dependent variable, time (t) is the independent variable\n",
      "and speed (v) is the controlled variable.\n",
      "\n",
      "5. While plotting the relationship of variables in a graph, the\n",
      "dependent variable is always plotted on the y-axis or the vertical\n",
      "line and the independent variable is plotted on the horizontal\n",
      "line or the x-axis. Therefore, the dependent variable is sometimes\n",
      "called the vertical variable or the y-variable and the independent\n",
      "variable is called the horizontal variable or the x-variable. Graph\n",
      "presentation always depicts how the change in the independent\n",
      "variable brings the change in the dependent variable.\n",
      "\n",
      "1.2 Types of units\n",
      "\n",
      "Physical quantities are measured in units. The units of all physical\n",
      "quantities can be divided into two types:\n",
      "\n",
      "ds Fundamental unit\n",
      "2. Derived unit\n",
      "Fundamental unit\n",
      "\n",
      "The unit of measurement which has its independent existence or\n",
      "does not depend upon the other units and cannot be resolved into\n",
      "any simpler forms is called the fundamental unit. For example, the\n",
      "fundamental unit of mass is kilogram, the fundamental unit of time is\n",
      "second, and the fundamental unit of length is metre. In the SI system,\n",
      "\n",
      "there are 7 fundamental units and they are listed below:\n",
      "\n",
      "Science and Technology, Grade 10 &\n",
      "\n",
      "temperature kelvin\n",
      "luminous intensity candela\n",
      "electric current ampere\n",
      "\n",
      "amount of substance\n",
      "\n",
      "Derived unit\n",
      "\n",
      "The unit of measurement which has no independent existence and is\n",
      "composed of two or more fundamental units is called a derived unit.\n",
      "For example, the unit of density is kg/m’. It consists of two fundamental\n",
      "units; kilogram and meter. Similarly, the unit of force is kgms*, where\n",
      "kilogram (kg), metre (m) and second (s) are the three fundamental units\n",
      "involved in it. It is difficult to say kgms-? in daily use andhence, this\n",
      "combined form of units is given a simpler name, newton (N). Therefore,\n",
      "N = Kgms-~’. Likewise, the unit of pressure is pascal (Pa). This unit is\n",
      "equal to kgm -'s*. In this way, units of many derived quantities are\n",
      "given a specific name.But in the case of some physical quantities, the\n",
      "combination of fundamental units in itself is in use, for example, unit\n",
      "\n",
      "of density is kgm-*.There is no simpler name for it.\n",
      "\n",
      "Quantity | Formula Combination of] Fundamental Derived\n",
      "base units accord-\n",
      "ing to the formula}.\n",
      "\n",
      "area [xb moter x motor |\n",
      "\n",
      "volume 1 xb xh —— x meter x} m°\n",
      "——\n",
      "\n",
      "density mass kilogram kg/m* kg/m?\n",
      "volume meter®\n",
      "\n",
      "velocity displacement meter m/s m/s\n",
      "time second\n",
      "\n",
      "Science and Technology, Grade 10\n",
      "\n",
      "\n",
      "accelera-_ | velocity meter m/s? m/s?\n",
      "tion — second X second\n",
      "mass xaccelera-|kilogram  x|kgm/s? Newton\n",
      "tion meter (N)\n",
      "pressure | force (kgm/s?) /meter? | kg/ms? Pascal\n",
      "\n",
      "“— _\n",
      "power work kgm?/s? kgm?/s* watt\n",
      "time eeeott (W)\n",
      "manne “\n",
      "frequency} 1 1 st Hz\n",
      "time Ss\n",
      "\n",
      "To find out the composition of derived unit which includes the\n",
      "fundamental units, analysis can be done based on the definition of\n",
      "the physical quantity. For example:\n",
      "\n",
      "a) The unit of area is square metre\n",
      "Analysis: Area = length x breadth\n",
      "\n",
      "=mxm\n",
      "=m?\n",
      "Therefore, the unit of area is m2. This unit is formed from two\n",
      "fundamental units.\n",
      "b) The unit of force is Newton (N)\n",
      "Analysis: According to the definition of force, F = ma\n",
      "The unit of mass (m) is kg and the unit of acceleration (a) is ms-?.\n",
      "\n",
      "Therefore, N = kgms-?. Hence kilogram, meter and second are the\n",
      "fundamental units and they are combined to form the unit of force\n",
      "\n",
      "which is called newton.\n",
      "\n",
      "Science and Technology, Grade 10 &\n",
      "\n",
      "Activity 1.2\n",
      "\n",
      "Find out the various units used to measure different kinds of physi-\n",
      "cal quantities in your daily life. Classify these units into two groups;\n",
      "\n",
      "fundamental and derived units and fill up the table as given below in\n",
      "\n",
      "your note copy.\n",
      "\n",
      "The difference between the fundamental unit and the derived unit\n",
      "is mentioned below:\n",
      "\n",
      "Fundamental unit Derived unit\n",
      "\n",
      "a) |It doesnot depend upon|a) |It depends upon the funda-\n",
      "other units. mental units.\n",
      "\n",
      "b) | There are seven fundamental | b) | Many derived units are formed\n",
      "units used till now. from seven fundamental units.\n",
      "\n",
      "Analysis of unitwise equation\n",
      "\n",
      "Various formulae and equations are obtained from the conclusion of\n",
      "scientific studies. The validity and uniformity of such formulae and\n",
      "equations can be checked by the analysis of units involved in such\n",
      "physical quantities. For the validation of an equation, units on both\n",
      "sides of an equation must be the same. Example: While performing\n",
      "the unit analysis of the equation: s=vxt, the fundamental unit of the\n",
      "quantity onthe left-hand side of the equation is m and the fundamen-\n",
      "tal unit of the quantity on the right-hand side of the equation is also\n",
      "ms-! X s = m. Therefore, this equation is valid.\n",
      "\n",
      "But, if someone claims s = v/t, then by performing the unit analysis,\n",
      "the fundamental unit of the quantity on the left-hand side is m but\n",
      "the fundamental unit of the quantity on the right-hand side is ms-1/s\n",
      "or ms-?. Hence the unit of physical quantity on the left-hand side of\n",
      "\n",
      "0 Science and Technology, Grade 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# Define a function to extract text from a page using PyMuPDF\n",
    "def extract_text_from_page(page):\n",
    "    text = page.get_text()\n",
    "    if text.strip():  # If text is found, return it\n",
    "        return text\n",
    "    else:  # Otherwise, use OCR\n",
    "        return None\n",
    "\n",
    "# Define a function to perform OCR on an image of a page\n",
    "def perform_ocr(image):\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "# Define a function to extract text from a PDF, handling both text and scanned pages\n",
    "def extract_text_from_pdf(pdf_path, start_page, end_page):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text_by_page = []\n",
    "\n",
    "    for page_num in range(start_page - 1, end_page):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = extract_text_from_page(page)\n",
    "        if text is None:\n",
    "            # If no text is found, convert the page to an image and perform OCR\n",
    "            images = convert_from_path(pdf_path, first_page=page_num+1, last_page=page_num+1)\n",
    "            text = perform_ocr(images[0])\n",
    "        text_by_page.append(text)\n",
    "    return text_by_page\n",
    "\n",
    "# Example usage for Chapter 1 (from page 1 to 14)\n",
    "pdf_path = \"looma_sample_book.pdf\"  # Replace with the path to your PDF\n",
    "chapter_1_text = extract_text_from_pdf(pdf_path, 5, 14)\n",
    "chapter_1_text = \"\\n\".join(chapter_1_text)\n",
    "\n",
    "# Display the extracted text\n",
    "print(chapter_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Chapter 1:\n",
      "The text discusses scientific units of measurement, specifically fundamental units and derived units. Fundamental units are those that have independent existence and cannot be resolved into simpler forms, such as the kilogram (mass), second (time), and meter (length). There are seven fundamental units in the SI system.\n",
      "\n",
      "Derived units, on the other hand, are composed of two or more fundamental units and do not exist independently. Examples include density (kg/m³) and force (N = kg·m/s²).\n",
      "\n",
      "The text also explains how derived units can be analyzed to determine their composition, using examples such as area (m²), force (N), and pressure (Pa). It also discusses the concept of unit analysis, where one checks that the units on both sides of an equation are the same. This is demonstrated through the example equation s = v·x·t, which is shown to be valid.\n",
      "\n",
      "Finally, the text provides a table for students to classify various units used in daily life into fundamental and derived units, and encourages them to perform unit analysis on equations to validate their accuracy.\n",
      "Summary saved to chapter_1_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"  # Ensure this is the correct URL for your local Llama3 instance\n",
    "\n",
    "def llama3(prompt):\n",
    "    data = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()['message']['content']\n",
    "\n",
    "# Generate summary for Chapter 1\n",
    "chapter_1_summary = llama3(f\"Summarize the following text: {chapter_1_text}\")\n",
    "\n",
    "print(f\"Summary of Chapter 1:\\n{chapter_1_summary}\")\n",
    "\n",
    "with open(\"chapter_1_summary.txt\", \"w\") as file:\n",
    "    file.write(chapter_1_summary)\n",
    "\n",
    "print(\"Summary saved to chapter_1_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
