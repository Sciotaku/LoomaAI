{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up Your Environment\n",
    "First, ensure you have Python installed on your system. Then, you'll need to install the necessary libraries. You can do this by running the following commands in your terminal or command prompt:\n",
    "pip install nltk transformers pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Text Processing with NLTK\n",
    "Here's how you can start with basic text processing tasks such as tokenization (breaking text into words or sentences) using NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Download necessary datasets\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"Here is an example sentence. And another one!\"\n",
    "\n",
    "# Tokenize into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentences:\", sentences)\n",
    "\n",
    "# Tokenize into words\n",
    "words = word_tokenize(text)\n",
    "print(\"Words:\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarization with Transformers\n",
    "For summarization, we'll use the transformers library to leverage a pre-trained model. This example uses the pipeline function for summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "text = \"\"\"\n",
    "Looma Education provides a comprehensive digital library accessible through various means, including a dedicated Looma box, servers in schools, and online through AWS. The system is designed to enrich the educational experience by integrating approved textbooks with a vast array of digital resources, making learning more engaging and effective.\n",
    "\"\"\"\n",
    "\n",
    "# Perform summarization\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "\n",
    "print(\"Summary:\", summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Extraction (Keyword Extraction) with Transformers\n",
    "While the Transformers library doesn't directly provide a \"topic extraction\" pipeline, you can use it for named entity recognition (NER) or keyphrase extraction as a proxy to identify important topics in a text. For more straightforward keyword extraction, you might explore other libraries or methods, but here's a basic NER example with Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\")\n",
    "\n",
    "text = \"Looma Education is enhancing learning in Nepal by integrating digital resources with traditional textbooks.\"\n",
    "\n",
    "# Perform NER\n",
    "ner_results = ner_pipeline(text)\n",
    "\n",
    "# Extract entities\n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Type: {entity['entity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
