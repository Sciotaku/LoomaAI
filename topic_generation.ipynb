{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['your_database_name']\n",
    "collection = db['your_collection_name']\n",
    "\n",
    "# Fetch the textbooks data\n",
    "textbooks = list(collection.find())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example structure of textbook document\n",
    "# {\n",
    "#   \"_id\": ObjectId(\"...\"),\n",
    "#   \"grade\": 1,\n",
    "#   \"chapter\": \"Introduction to Science\",\n",
    "#   \"content\": \"Text of the chapter...\"\n",
    "# }\n",
    "\n",
    "texts = [textbook['content'] for textbook in textbooks if 'content' in textbook]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load spaCy model and stop words\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Preprocess all texts\n",
    "preprocessed_texts = [preprocess(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Create Dictionary and Corpus\n",
    "dictionary = corpora.Dictionary(preprocessed_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in preprocessed_texts]\n",
    "\n",
    "# Apply LDA\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, random_state=100, passes=10, per_word_topics=True)\n",
    "\n",
    "# Save the model for later use\n",
    "lda_model.save('lda_model.model')\n",
    "\n",
    "# Display topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis, 'lda_visualization.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, textbook in enumerate(textbooks):\n",
    "    bow = dictionary.doc2bow(preprocessed_texts[idx])\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # Assuming you want to store the top 3 topics\n",
    "    top_topics = sorted(topics, key=lambda x: -x[1])[:3]\n",
    "    topic_ids = [topic[0] for topic in top_topics]\n",
    "    \n",
    "    # Update the document in MongoDB\n",
    "    collection.update_one({'_id': textbook['_id']}, {'$set': {'topics': topic_ids}})\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
